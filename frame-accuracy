#!/usr/bin/python3

from os import path
import json
from fractions import Fraction
from hashlib import md5

import gi
gi.require_version('Gst', '1.0')
from gi.repository import GObject, Gst
from novacut.misc import random_slice
from novacut.timefuncs import video_pts_and_duration


GObject.threads_init()
Gst.init(None)
tree = path.dirname(path.abspath(__file__))
filename = path.join(tree, 'MVI_5751.MOV')
uri = 'file://' + filename


# We know our test video has 107 frames and a framerate of 30000/1001
framerate = Fraction(30000, 1001)
frames = 107



class Test:
    def __init__(self, slices, expected):
        self.expected = expected
        self.i = 0
        self.match = True

        self.mainloop = GObject.MainLoop()
        self.pipeline = Gst.Pipeline()
        self.bus = self.pipeline.get_bus()
        self.bus.add_signal_watch()
        self.bus.connect('message::eos', self.on_eos)
        self.bus.connect('message::error', self.on_error)

        # You need a gnlcomposition for video, and another for audio, but in
        # this example, we'll just do video:
        self.comp = Gst.ElementFactory.make('gnlcomposition', None)
        self.identity = Gst.ElementFactory.make('identity', None)
        self.sink = Gst.ElementFactory.make('fakesink', None)

        # Add elements to pipeline
        self.pipeline.add(self.comp)
        self.pipeline.add(self.identity)
        self.pipeline.add(self.sink)

        # Set properties
        self.identity.set_property('single-segment', True)
        self.sink.set_property('signal-handoffs', True)

        # Link elements
        self.identity.link(self.sink)

        # Connect signal handlers
        self.comp.connect('pad-added', self.on_pad_added)
        self.sink.connect('handoff', self.on_handoff)

        # Now build the slices, add to compositions.
        offset = 0
        for s in slices:
            # Create the elements, set the URI:
            src = Gst.ElementFactory.make('gnlurisource', None)
            src.set_property('uri', uri)

            # Select the appropriate media stream
            src.set_property('caps', Gst.caps_from_string('video/x-raw'))

            # Length of slice in frames
            frames = s.stop - s.start

            # These properties are about the slice itself
            (pts, dur) = video_pts_and_duration(
                s.start, s.stop, framerate
            )
            src.set_property('media-start', pts)
            src.set_property('media-duration', dur)

            # These properties are about the position of the slice in the
            # composition:
            (pts, dur) = video_pts_and_duration(
                offset, offset + frames, framerate
            )
            src.set_property('start', pts)
            src.set_property('duration', dur)

            # Add slice to the composition:
            self.comp.add(src)
            offset += frames

    def run(self):
        self.pipeline.set_state(Gst.State.PLAYING)
        self.mainloop.run()

    def kill(self):
        self.pipeline.set_state(Gst.State.NULL)
        self.mainloop.quit()

    def on_pad_added(self, element, pad):
        string = pad.query_caps(None).to_string()
        print('on_pad_added:', string)
        if string.startswith('video/'):
            pad.link(self.identity.get_static_pad('sink'))

    def on_handoff(self, element, buf, pad):
        map_info = buf.map_range(0, -1, Gst.MapFlags.READ)[1]
        data = map_info.to_bytes().unref_to_array()
        got = md5(data).hexdigest()
        expected = self.expected[self.i]
        if got != expected:
            self.match = False
            status = '!'
        else:
            status = '='
        print(status, got, expected, self.i)
        self.i += 1

    def on_eos(self, bus, msg):
        print('on_eos()')
        self.kill()

    def on_error(self, bus, msg):
        print('on_error():', msg.parse_error())
        self.kill()


hashes = json.load(open('frames.json', 'r'))
expected = []
slices = []
for i in range(25):
    s = random_slice(frames)
    slices.append(s)
    expected.extend(
        hashes[f] for f in range(s.start, s.stop)  
    )

test = Test(tuple(slices), tuple(expected))
test.run()
print('match:', test.match)
print('frames:', len(expected))
    

